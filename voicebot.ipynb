{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install grpcio\n",
    "! pip install grpcio-tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('protos'): os.makedirs('protos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile protos/chatbot.proto\n",
    "syntax = \"proto3\";\n",
    "\n",
    "package chatPack;\n",
    "\n",
    "service ChatService {\n",
    "  rpc ChatFunc (ChatRequest) returns (ChatReply) {}\n",
    "}\n",
    "\n",
    "message ChatRequest {\n",
    "  string name = 1;\n",
    "}\n",
    "message ChatReply {\n",
    "  string result = 1;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m grpc_tools.protoc -I protos/ --python_out=protos/ --grpc_python_out=protos/ chatbot.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('chatbot'): os.makedirs('chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot/server.py\n",
    "from concurrent import futures\n",
    "import logging\n",
    "\n",
    "import grpc\n",
    "import sys\n",
    "sys.path.append(\"protos\")\n",
    "import chatbot_pb2\n",
    "import chatbot_pb2_grpc\n",
    "sys.path.append(\"configs\")\n",
    "import config\n",
    "\n",
    "class ChatService(chatbot_pb2_grpc.ChatService):\n",
    "\n",
    "    def ChatFunc(self, request, context):\n",
    "        return chatbot_pb2.ChatReply(result='Chatbot:%s' % request.name)\n",
    "\n",
    "def serve():\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    chatbot_pb2_grpc.add_ChatServiceServicer_to_server(ChatService(), server)\n",
    "    server.add_insecure_port('[::]:'+str(config.chatbot))\n",
    "    server.start()\n",
    "    server.wait_for_termination()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig()\n",
    "    serve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start chatbot server\n",
    "python chatbot/server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot client received: Vaja client received: Vaja:blue\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "import sys\n",
    "sys.path.append(\"protos\")\n",
    "import chatbot_pb2\n",
    "import chatbot_pb2_grpc\n",
    "sys.path.append(\"configs\")\n",
    "import config\n",
    "\n",
    "def chatBotClient():\n",
    "    with grpc.insecure_channel('localhost:'+str(config.chatbot)) as channel:\n",
    "        stub = chatbot_pb2_grpc.ChatServiceStub(channel)\n",
    "        response = stub.ChatFunc(chatbot_pb2.ChatRequest(name='blue'))\n",
    "    print(\"Chatbot client received: \" + response.result)\n",
    "chatBotClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting protos/vaja.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile protos/vaja.proto\n",
    "syntax = \"proto3\";\n",
    "\n",
    "package vajaPack;\n",
    "\n",
    "service VajaService {\n",
    "  rpc VajaFunc (VajaRequest) returns (VajaReply) {}\n",
    "  rpc VajaStream (stream StreamData) returns (VajaReply) {}\n",
    "  rpc VajaBiStream (stream StreamData) returns (stream StreamData) {}\n",
    "}\n",
    "\n",
    "message VajaRequest {\n",
    "  string name = 1;\n",
    "}\n",
    "message VajaReply {\n",
    "  string result = 1;\n",
    "}\n",
    "message StreamData {\n",
    "  string check = 1;\n",
    "  string data = 2;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m grpc_tools.protoc -I protos/ --python_out=protos/ --grpc_python_out=protos/ vaja.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('vaja'): os.makedirs('vaja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vaja/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile vaja/server.py\n",
    "from concurrent import futures\n",
    "import logging\n",
    "\n",
    "import grpc\n",
    "import sys\n",
    "sys.path.append(\"protos\")\n",
    "import vaja_pb2\n",
    "import vaja_pb2_grpc\n",
    "sys.path.append(\"configs\")\n",
    "import config\n",
    "\n",
    "class VajaService(vaja_pb2_grpc.VajaService):\n",
    "\n",
    "    def VajaFunc(self, request, context):\n",
    "        print('Recive data:'+request.name)\n",
    "        return vaja_pb2.VajaReply(result='Vaja:%s' % request.name)\n",
    "\n",
    "    def VajaStream(self, request_iterator, context):\n",
    "        for new_data in request_iterator:\n",
    "            print('Stream Recive data:'+new_data.check+':'+new_data.data)\n",
    "        print('End Stream.')\n",
    "        return vaja_pb2.VajaReply(result='Vaja:stream')\n",
    "\n",
    "    def VajaBiStream(self, request_iterator, context):\n",
    "        for new_data in request_iterator:\n",
    "            print('BiStream Recive data:'+new_data.check+':'+new_data.data)\n",
    "            yield vaja_pb2.StreamData(check='1',data=new_data.data+' ok')\n",
    "        print('End BiStream.')\n",
    "\n",
    "def serve():\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    vaja_pb2_grpc.add_VajaServiceServicer_to_server(VajaService(), server)\n",
    "    server.add_insecure_port('[::]:'+str(config.vaja))\n",
    "    server.start()\n",
    "    server.wait_for_termination()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig()\n",
    "    serve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start chatbot server\n",
    "python vaja/server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VajaFunc client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaja client received: Vaja:blue\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "import sys\n",
    "sys.path.append(\"protos\")\n",
    "import vaja_pb2\n",
    "import vaja_pb2_grpc\n",
    "sys.path.append(\"configs\")\n",
    "import config\n",
    "\n",
    "def vajaClient():\n",
    "    with grpc.insecure_channel('localhost:'+str(config.vaja)) as channel:\n",
    "        stub = vaja_pb2_grpc.VajaServiceStub(channel)\n",
    "        response = stub.VajaFunc(vaja_pb2.VajaRequest(name='blue'))\n",
    "        print(\"Vaja client received: \" + response.result)\n",
    "vajaClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stream client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaja stream client received: Vaja:stream\n",
      "Vaja biStream client received: 1:zero ok\n",
      "Vaja biStream client received: 1:one ok\n",
      "Vaja biStream client received: 1:two ok\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "import sys\n",
    "sys.path.append(\"protos\")\n",
    "import vaja_pb2\n",
    "import vaja_pb2_grpc\n",
    "sys.path.append(\"configs\")\n",
    "import config\n",
    "def make_data(check, data):\n",
    "    return vaja_pb2.StreamData(\n",
    "        check=check,\n",
    "        data=data)\n",
    "def generate_messages():\n",
    "    messages = [\n",
    "        make_data('0','zero'),\n",
    "        make_data('0','one'),\n",
    "        make_data('0','two'),\n",
    "    ]\n",
    "    for msg in messages:\n",
    "        yield msg\n",
    "def streamClient(stub):\n",
    "    response = stub.VajaStream(generate_messages())\n",
    "    print(\"Vaja stream client received: \" + response.result)\n",
    "def biStreamClient(stub): \n",
    "    response = stub.VajaBiStream(generate_messages())\n",
    "    for resp in response:\n",
    "        print(\"Vaja biStream client received: \" + str(resp.check) + ':' + resp.data)\n",
    "def run():\n",
    "    with grpc.insecure_channel('localhost:'+str(config.vaja)) as channel:\n",
    "        stub = vaja_pb2_grpc.VajaServiceStub(channel)\n",
    "        streamClient(stub)\n",
    "        biStreamClient(stub)\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaja to Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot/vajaClient.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot/vajaClient.py\n",
    "import grpc\n",
    "import sys\n",
    "sys.path.append(\"protos\")\n",
    "import vaja_pb2\n",
    "import vaja_pb2_grpc\n",
    "sys.path.append(\"configs\")\n",
    "import config\n",
    "\n",
    "def vajaClient(nameInput):\n",
    "    with grpc.insecure_channel('localhost:'+str(config.vaja)) as channel:\n",
    "        stub = vaja_pb2_grpc.VajaServiceStub(channel)\n",
    "        response = stub.VajaFunc(vaja_pb2.VajaRequest(name=nameInput))\n",
    "    return \"Vaja client received: \" + response.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot/server.py\n",
    "from concurrent import futures\n",
    "import logging\n",
    "\n",
    "import grpc\n",
    "import sys\n",
    "sys.path.append(\"protos\")\n",
    "import chatbot_pb2\n",
    "import chatbot_pb2_grpc\n",
    "sys.path.append(\"configs\")\n",
    "import config\n",
    "\n",
    "import vajaClient\n",
    "\n",
    "class ChatService(chatbot_pb2_grpc.ChatService):\n",
    "\n",
    "    def ChatFunc(self, request, context):\n",
    "        return chatbot_pb2.ChatReply(result=vajaClient.vajaClient(request.name))\n",
    "\n",
    "def serve():\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    chatbot_pb2_grpc.add_ChatServiceServicer_to_server(ChatService(), server)\n",
    "    server.add_insecure_port('[::]:'+str(config.chatbot))\n",
    "    server.start()\n",
    "    server.wait_for_termination()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig()\n",
    "    serve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patii\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r FastApi/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start server\n",
    "uvicorn main:app --reload --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Hello': 'blue'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('http://localhost:8080/?name=blue')\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Hello': 'blue:38 year old.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://localhost:8080/'\n",
    "payload = {\n",
    "      'name':'blue',\n",
    "      'age':38\n",
    "      }\n",
    "\n",
    "response = requests.post(url, data = payload)\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Hello': 'blue:38 year old.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://localhost:8080/json'\n",
    "payload = {\n",
    "      'name':'blue',\n",
    "      'age':38\n",
    "      }\n",
    "\n",
    "response = requests.post(url, json = payload)\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'item_id': 26, 'q': 'blue'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('http://localhost:8080/items/26?q=blue')\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gRPC Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Route to': 'blue', 'ret': 'Chat client received: Vaja client received: Vaja:blue'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('http://localhost:8080/route?name=blue')\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json input\n",
    "???"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "826a4dec6dbd334b37b0b009e016c602b3381788eafcd6b52e7e7aa795b25baf"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('grpc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
